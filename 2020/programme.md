---
layout: cvmp-default
title: Conference Programme
year: 2020
---
<span class="label label-info"><b>Please note:</b></span>
<em>All times are given in <a href="https://time.is/GMT">GMT (UTC+0)</a>. This programme is preliminary and subject to change.</em>

<div class="col-12 col-sm-12 col-lg-12">
	<a name="Monday"></a>
	<div class="panel panel-default">
		<div class="panel-heading"><b>Monday, 7th December 2020</b></div>
		<table class="table table-striped">
			<tr>
				<td>09:00</td>
				<td><b>Morning Coffee Networking</b></td>
			</tr>
			<tr>
				<td>10:00</td>
				<td><b>Chair’s Welcome</b><br/>Christian Richardt (Conference Chair), <i>University of Bath</i></td>
			</tr>
			<tr>
				<td>10:10</td>
				<td><b>Paper Session 1: Learning</b><br/>
					<ul>
						<li>Neural Face Models for Example-Based Visual Speech Synthesis<br/><i>Wolfgang Paier, Anna Hilsmann and Peter Eisert (Fraunhofer Heinrich Hertz Institute)</i></li>
						<li>Constant Velocity Constraints for Self-Supervised Monocular Depth Estimation<br/><i>Hang Zhou, David Greenwood, Sarah Taylor and Han Gong (University of East Anglia)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>11:00</td><td><a href="/2020/keynotes/#ST"><b>Keynote: Immersive Art and Healthcare</b></a><br/>Sarah Ticho, <i>Founder of Hatsumi, producer at Deep and Healthcare Lead at Immerse UK</i></td>
			</tr>
			<tr>
				<td>12:00</td>
				<td><b>Networking Lunch</b></td>
			</tr>
			<tr>
				<td>14:00</td>
				<td><b>Industry Talk</b><br/><i>to be confirmed</i></td>
			</tr>
			<tr>
				<td>14:20</td>
				<td><b>Short Papers and Demo Session</b><br/>
					<ul>
						<li><a target ="_blank" href="/files/2020/short/6.pdf">From a Still Image to a Semantically Aware Video: A Context and Metadata-driven Automatic Media Production Framework</a><br/><i>Paula Viana (Polytechnic of Porto, INESC TEC Porto), Pedro Carvalho (INESC TEC Porto, Polytechnic of Porto), Maria Teresa Andrade (University of Porto, INESC TEC Porto), Inês N. Teixeira (Polytechnic of Porto, INESC TEC Porto, University of Porto), Pieter P. Jonker (QdepQ Systems), Luís Vilaça (University of Porto, INESC TEC Porto, Polytechnic of Porto), José Pedro Pinto (INESC TEC Porto) and Tiago Costa (INESC TEC Porto, University of Porto) </i></li>
						<li><a target ="_blank" href="/files/2020/short/11.pdf">Artistic Control of Defocus in Computer-Generated Holography</a><br/><i>Aaron Demolder (National Centre for Computer Animation, Bournemouth University), Andrzej Kaczorowski (VividQ Ltd), Alfred Newman (VividQ Ltd) and Hammadi Nait-Charif (National Centre for Computer Animation, Bournemouth University)</i></li>
						<li><a target ="_blank" href="/files/2020/short/12.pdf">Estimating Specular Anisotropy Angle with Polarized Photometric Stereo Setup</a><br/><i>Arvin Lin, Yiming Lin and Abhijeet Ghosh (Imperial College London)</i></li>
						<li><a target ="_blank" href="/files/2020/short/13.pdf">Performance Optimization of Neural Style Transfer for Animated Characters in Real-Time Rendering</a><br/><i>Katsushi Suzuki, Takeshi Okuya and Misumi Hata (Research & Development Office, DELiGHTWORKS Inc.)</i></li>						
						<li><a target ="_blank" href="/files/2020/short/16.pdf">Super-Resolution Appearance Transfer for 4D Human Performance Capture</a><br/><i>Marco Pesavento, Marco Volino and Adrian Hilton (CVSSP, University of Surrey)</i></li>
						<li><a target ="_blank" href="/files/2020/short/17.pdf">Real-Time Monocular 6DoF Object Pose Tracking on Smartphone GPUs</a><br/><i>Valentin Miu (Centre for Digital Entertainment, Bournemouth University, Beauty Labs International Ltd) and Oleg Fryazinov (National Centre for Computer Animation, Bournemouth University)</i></li>
						<li><a target ="_blank" href="/files/2020/demo/15.pdf">OmniPhotos: Casual 360° VR Photography with Motion Parallax</a><br/><i>Tobias Bertel, Mingze Yuan, Reuben Lindroos and Christian Richardt (University of Bath)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>15:00</td>
				<td><b>Coffee Break with Q&amp;A and Networking</b></td>
			</tr>
			<tr>
				<td>16:00</td><td><a href="/2020/keynotes/#PD"><b>Keynote: Light Stages, and the Future of Virtual Production</b></a><br/>Paul Debevec, <i>Senior Staff Scientist, Google Research</i></td>
			</tr>
			<tr>
				<td>17:00</td>
				<td><b>CDE Networking Reception</b><br/><i>To be confirmed.</i></td>
			</tr>
		</table>
	</div>
	<a name="Tuesday"></a>
	<div class="panel panel-default">
		<div class="panel-heading"><b>Tuesday, 8th December 2020</b></div>
		<table class="table table-striped">
			<tr>
				<td>09:00</td>
				<td><b>Morning Coffee Networking</b></td>
			</tr>
			<tr>
				<td>10:00</td>
				<td><b>Paper Session 2: Production</b><br/>
					<ul>
						<li>High Fidelity Interactive Video Segmentation Using Tensor Decomposition, Boundary Loss, Convolutional Tessellations, and Context-Aware Skip Connections<br/><i>Anthony D. Rhodes and Manan Goel (Intel Corporation)</i></li>
						<li>Image Decomposition using Geometric Region Colour Unmixing<br/><i>Mairead Grogan and Aljosa Smolic (Trinity College Dublin)</i></li>
						<li>Exploring the Use of Skeletal Tracking for Cheaper Motion Graphs and On-Set Decision Making in Free-Viewpoint Video Production<br/><i>Andrew D. MacQuarrie and Anthony Steed (University College London)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>11:00</td><td><a href="/2020/keynotes/"><b>Keynote: To Be Announced</b></a><!--<br/>Sarah Ticho, <i>Founder of Hatsumi, producer at Deep and Healthcare Lead at Immerse UK</i>--></td>
			</tr>
			<tr>
				<td>12:00</td>
				<td><b>Networking Lunch</b></td>
			</tr>
			<tr>
				<td>14:00</td>
				<td><b>Special Session on Virtual Production</b><br/><i>To be confirmed.</i></td>
			</tr>
			<tr>
				<td>15:00</td>
				<td><b>Coffee Break with Q&amp;A and Networking</b></td>
			</tr>
			<tr>
				<td>16:00</td><td><a href="/2020/keynotes/#AK"><b>Keynote: Perceiving Humans and Objects in the 3D World</b></a><br/>Angjoo Kanazawa, <i>UC Berkeley</i></td>
			</tr>
			<tr>
				<td>17:00</td>
				<td><b>Prizes, Announcements and Closing Remarks</b></td>
			</tr>
		</table>
	</div>
</div>
