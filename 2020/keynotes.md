---
layout: cvmp-default
title: Keynotes
year: 2020
---

We are pleased to announce the following keynote speakers for CVMP 2020:


<a name="AK" />
<div class="row">
<div class="col-xs-12 col-sm-7 col-md-8 col-lg-9" markdown="1" style="text-align: justify">

#### Angjoo Kanazawa, UC Berkeley <br> Perceiving Humans and Objects in the 3D World


*Angjoo Kanazawa is an Assistant Professor in the Department of Electrical Engineering and Computer Sciences at the University of California, Berkeley. She is also a Research Scientist at Google Research. Her research lies at the intersection of computer vision, computer graphics, and machine learning. The goal of her lab is to build a system that can capture, perceive, and understand the underlying dynamic 3D world behind everyday photographs and videos, including deformable objects such as humans and animals. Previously, Prof. Kanazawa was a BAIR postdoc at UC Berkeley advised by Jitendra Malik, Alexei A. Efros and Trevor Darrell. She completed her PhD in Computer Science at the University of Maryland, College Park advised by David Jacobs. During her PhD, she had the pleasure to visit the Max Planck Institute in Tübingen, Germany under the guidance of Michael Black. Prior to that, Prof. Kanazawa completed her BA in Mathematics and Computer Science at NYU. She has been named a Rising Star in EECS and is a recipient of Anita Borg Memorial Scholarship. Her work on learning 3D deformation of animals from 2D images won the best paper award at Eurographics 2016.*

</div>

<figure class="col-xs-6 col-sm-5 col-md-4 col-lg-3">
  <img src="{{site.url}}/img/2020/keynotes/AngjooKanazawa-800.jpg" class="img-responsive img-thumbnail" alt="Angjoo Kanazawa " title="Angjoo Kanazawa">
</figure>

</div>


<a name="PD" />
<div class="row">
<div class="col-xs-12 col-sm-7 col-md-8 col-lg-9" markdown="1" style="text-align: justify">

#### Paul Debevec, Senior Staff Scientist, Google Research <br> Light Fields, Light Stages, and the Future of Virtual Production

In this talk I'll describe the latest work we've done at Google and the USC Institute for Creative Technologies to bridge the real and virtual worlds through photography, lighting, and machine learning.  I'll begin by describing our new DeepView solution for Light Field Video: Immersive Motion Pictures that you can move around in after they have been recorded.  Our latest light field video techniques record six-degrees-of-freedom virtual reality where subjects can come close enough to be within arm's reach.  I'll also present how Google's new Light Stage system paired with Machine Learning techniques is enabling new techniques for lighting estimation from faces for AR and interactive portrait relighting on mobile phone hardware.  I will finally talk about how both of these techniques may enable the next advances in virtual production filmmaking, infusing both light fields and relighting into the real-time image-based lighting techniques now revolutionizing how movies and television are made.

*Paul is a Senior Staff Scientist at Google Research and an Adjunct Research Professor at the USC Institute for Creative Technologies. His research in HDR imaging, image-based lighting, and photoreal digital actors has been recognized with two technical Academy Awards and SMPTE’s 2017 Progress Medal.  In the early 2000’s, he originated the technique of surrounding actors with LED displays to create on-set image-based lighting for virtual production.  Techniques from his work have been used to create key visual effects sequences in The Matrix, Spider-Man 2, Benjamin Button, Avatar, Gravity, Furious 7, Gemini Man, and to create a 3D Portrait of US President Barack Obama.  More info at: <http://www.debevec.org>.*

</div>

<figure class="col-xs-6 col-sm-5 col-md-4 col-lg-3">
  <img src="{{site.url}}/img/2020/keynotes/PaulDebevec.jpg" class="img-responsive img-thumbnail" alt="Paul Debevec" title="Paul Debevec">
</figure>

</div>


<a name="ST" />
<div class="row">
<div class="col-xs-12 col-sm-7 col-md-8 col-lg-9" markdown="1" style="text-align: justify">

#### Sarah Ticho, Founder of Hatsumi <br> Immersive Art and Healthcare

Sarah Ticho is the founder of [Hatsumi](https://www.hatsumivr.com/), producer at [Deep](http://www.exploredeep.com/) and Healthcare Lead at [Immerse UK](https://www.immerseuk.org/).  During this talk, she will discuss the applications of immersive technology in healthcare to support patients, educate clinicians and help inject a bit of fun into the recovery process. This talk will emphasise the importance of supporting cross-disciplinary collaborations between researchers, healthcare professionals, patients and creative practitioners which can support new innovative discoveries and opportunities for impact. She will share her experience of developing Hatsumi: a virtual reality adaptation of arts and health research method; body mapping which enables people to visualise the embodied experience of pain and emotion using 3D drawing and sound. Through digitising the process it can enhance its potential as a tool to improve patient-doctor communication, enhance research into the phenomenology of pain and emotion and create new creative tools to change the conversation around invisible experiences.

*Sarah plays an instrumental role in shaping the future of immersive technology in healthcare.  She is a consultant, researcher, curator and practitioner, and has worked with leading organisations including YouTube VR Creators Lab, The Big Anxiety Festival, Nesta, The Knowledge Transfer Network, NHS and the Institution of Engineering and Technology amongst others. She is the founder of virtual reality health tech startup Hatsumi, and the producer at Explore Deep, an award-winning clinically validated breath controlled VR experience designed to reduce anxiety. She continues to nurture the UK VR healthcare community through her role as Healthcare Lead at Immerse UK, and sits on the XR Safety Initiatve’s Medical XR advisory council.*

</div>

<figure class="col-xs-6 col-sm-5 col-md-4 col-lg-3">
  <img src="{{site.url}}/img/2020/keynotes/SarahTicho-800.jpg" class="img-responsive img-thumbnail" alt="Sarah Ticho" title="Sarah Ticho">
</figure>

</div>
