---
layout: cvmp-default
title: Conference Programme
year: 2023
---
##### Noted that this program is tentative and subject to change

<strong>Programme booklet:</strong>
[CVMP 2023 Programme (9.6 MB)]({{ site.url }}/files/2023/CVMP23-brochure.pdf)

<strong>Conference proceedings:</strong>
[ACM Digital Library](https://dl.acm.org/doi/proceedings/10.1145/3626495){:target="_blank"}


<div class="col-12 col-sm-12 col-lg-12">
	<a name="thursday"></a>
	<div class="panel panel-default">
		<div class="panel-heading"><b>Thursday 30th November 2023</b></div>
		<table class="table table-striped">
			<tr>
				<td>09:00</td>
				<td><b>Registration opens</b></td>
			</tr>
			<tr>
				<td>09:20</td>
				<td><b>Welcome</b><br/>Marco Volino, <i>University of Surrey</i> </td>
			</tr>
			<tr>
				<td>09:30</td>
				<td><b>Session #1: Image-based AI</b><br/>
					<ul>
						<li>HDR Illumination Outpainting with a Two-Stage GAN Model<br/><i>Jack Hilliard, Adrian Hilton, Jean-Yves Guillemaut</i></li>
						<li>One-shot Detail Retouching with Patch Space Neural Transformation Blending<br/><i>Fazilet Gokbudak, Cengiz Oztireli</i></li>
						<li>A Compact and Semantic Latent Space for Disentangled and Controllable Image Editing<br/><i>Gwilherm Lesné, Yann Gousseau, Saïd Ladjal, Alasdair Newson</i></li>
						<li>DECORAIT - DECentralized Opt-in/out Registry for AI Training<br/><i>Kar Balan, Alex Black, Andrew Gilbert, Simon Jenni, Andy Parsons, John Collomosse</i></li>
                        <li>Expression-aware video inpainting for HMD removal in XR applications<br/><i>Fatemeh Ghorbani Lohesara, Karen Eguiazarian, Sebastian Knorr</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>11:10</td>
				<td><b>Coffee Break</b><br/><i></i></td>
			</tr>	
			<tr>
				<td>11:40</td>
				<td><a href="/2023/keynotes/#AW"><b>Keynote: The Magic of The Man in the Hat: Creating VFX for Indiana Jones and the Dial of Destiny</b></a><br/>Andrew Whitehurst, <i>Industrial Light and Magic</i></td>
			</tr>
			<tr>
				<td>12:40</td>
				<td><b>Spotlight Session-Short Papers and Demos</b><br/>
					<ul>
                    <b>Presented: 30th November</b>
						<li>Light Field Video Compression Efficiency Through View Omission and Synthesis<br/><i>Nusrat Mehajabin (University of British Columbia); Tala Bazzaza (University of British Columbia); Hamid Reza Tohidypour (University of British Columbia)*; Yixiao Wang (University of British Columbia); Panos Nasiopoulos (University of British Columbia)</i></li>
						<li>Human Pose Estimation Assisted Posture Reminder for E-Learning Video Production<br/><i>Yixia Zhao (Computer Network Information Center, Chinese Academy of Sciences)*; Zhenhua Feng (University of Surrey)</i></li>
						<li>Practical Imaging and Analysis of Turbidity in Liquid<br/><i>Kewei Li (Imperial College London)*; Abhijeet Ghosh (Imperial College London)</i></li>
						<li>SDiT: Enhanced Stable Diffusion for Audio-to-Talking Face Generation <br/><i>Fatemeh Nazarieh (University of Surrey)*; Zhenhua Feng (University of Surrey)</i></li>
						<li>So you think you can dance? Controllable Multi-person Dance Generation<br/><i>Emily Corby (University of Surrey)*; Andrew Gilbert (University of Surrey); Edward Fish (University of Surrey)</i></li>
						<li>InclusivityXR – an online tool for detecting inclusivity issues in AR and VR<br/><i>Andy T Woods (StoryFutures)*; Umar Farooq (University of Surrey); James Bennett (StoryFutures); Marco Volino (University of Surrey)</i></li>
                    <b>Presented: 1st December</b>
                        <li>Towards Neural Representations of Heterogeneous Translucent Voxelised Media<br/><i>Thomas Gillooly (Norwegian University of Science and Technology)*; Jon Yngve Hardeberg (NTNU); Abhijeet Ghosh (Imperial College London); Giuseppe Claudio Guarnera (University of York)</i></li>
						<li>Refocus-NeRF: Focus-Distance-Aware Neural Radiance Fields Trained with Focus Bracket Photography<br/><i>Yuki Yabumoto (Shibaura Institute of Technology)*; Takuhiro Nishida (Shibaura Institute of Technology); Takashi Ijiri (Shibaura Institute of Technology)</i></li>
						<li>MV-SyDog: A Multi-View 3D Dog Pose Dataset for Advancing 3D Pose Estimation<br/><i>Moira C Shooter (University of Surrey)*; Charles Malleson (University of Surrey); Adrian Hilton (University of Surrey)</i></li>
						<li>AI Robotic Camera System for Live Soccer Broadcasts<br/><i>Kota Takahashi (Japan Broadcasting Corporation)*; Toshie Misu (Japan Broadcasting Corporation); Kensuke Hisatomi ( Japan Broadcasting Corporation)</i></li>
						<li>Depth Reprojection for Mitigating Latency in XR Media Production<br/><i>Dominic Brown (disguise Technologies Ltd)*; Sebastian Day (disguise Technologies Ltd); Tom Whittock (disguise Technologies Ltd)</i></li>
						<li>Real-time omnidirectional 3D multi-person human pose estimation with occlusion handling<br/><i>Pawel M Knap (University of Southampton)*; Peter TD Hardy (University of Southampton); Alberto Tamajo (University of Southampton); Hwasup Lim (Korea Institute of Science and Technology); Hansung Kim (University Of Southampton)</i></li>
					<b>Demo Presentation</b>	
                        <li>Using ML networks for turning 2D video into 3D Volumetric Video inside of Unreal Engine 5 <br/><i>Alex Grona (Velox XR Limited)*</i></li>
						<li>Drawing from Motion Capture: Performance, 3D Drawing and Character Animation<br/><i>Ricardo Megre (AIM Creative Studios)*</i></li>
						<li>LightMoCap: Light-weight, Real-time & Scalable Markerless Motion Capture <br/><i>Georgios Albanis (University of Thessaly)*; NIKOLAOS ZIOULIS (Independent Researcher); Anargyros Chatzitofis (Moverse); Spyridon Thermos (Moverse); Vladimiros Sterzentsenko (CERTH); Kostas Kolomvatsos (University of Thessaly)</i></li>
						<li>Audio-Driven Video Composition<br/><i>Tim Rumpf (Filmuniversity Babelsberg Konrad Wolf); Jakub Fiser (Adobe Research)*</i></li>
                    </ul>
				</td>
			</tr>
			<tr>
				<td>13:00</td>
				<td><b>Lunch, Posters and Demos</b></td>
			</tr>
			<tr>
				<td>14:30</td>
				<td><b>Session #2: Pose and Motion</b><br/>
					<ul>
						<li>Optimising 2D Pose Representations: Improving Accuracy, Stability and Generalisability Within Unsupervised 2D-3D Human Pose Estimation<br/><i>Peter Hardy, Srinandan Dasmahapatra, Hansung Kim</i></li>
						<li>BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse Multiview Videos<br/><i>Georgios Albanis, Nikolaos Zioulis, Kostas Kolomvatsos</i></li>
						<li>CVMP Awards <br/><i>Jeff Clifford</i></li>
					</ul>
				</td>
			</tr>		
			<tr>
				<td>15:30</td>
				<td><b>Coffee Break</b></td>
			</tr>	
			<tr>
				<td>16:00</td>
				<td><a href="/2023/keynotes/#JS"><b>Keynote: Digital Humans in Generative Video</b></a><br/>Jonathan Starck, <i>Synthesia</i></td>
			</tr>
			<tr>
				<td>17:00</td>
				<td><b>Networking Reception</b></td>
			</tr>
		</table>
	</div>
	<a name="friday"></a>
	<div class="panel panel-default">
		<div class="panel-heading"><b>Friday 1st December 2023</b></div>
		<table class="table table-striped">
			<tr>
				<td>09:00</td>
				<td><b>Registration opens</b></td>
			</tr>
			<tr>
				<td>09:30</td>
				<td><b>Session #3: Image Processing and Reconstruction</b><br/>
					<ul>
						<li>Redistributing the Precision and Content in 3D-LUT-based Inverse Tone-mapping for HDR/WCG Display<br/><i>Cheng Guo, Leidong Fan, Qian Zhang, Hanyuan Liu, Kanglin Liu, Xiuhua Jiang</i></li>
						<li>A software test bed for sharing and evaluating color transfer algorithms for images and 3D objects<br/><i>Herbert Potechius, Gunasekaran Raja, Thomas Sikora, Sebastian Knorr</i></li>
						<li>LFSphereNet: Real Time Spherical Light Field Reconstruction from a Single Omnidirectional Image<br/><i>Manu Gond, Emin Zerman, Sebastian Knorr, Mårten Sjöström</i></li>
						<li>View-dependent Adaptive HLOD: real-time interactive rendering of multi-resolution models<br/><i>Rui Li</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>10:50</td>
				<td><b>Coffee Break</b></td>
			</tr>	
			<tr>
				<td>11:20</td><td><a href="/2023/keynotes/#DC"><b>Keynote: Towards Multi-Modal Generation</b></a><br/>Duygu Ceylan, <i>Adobe Research</i></td>
			</tr>
			<tr>
				<td>12:20</td>
				<td><b>Lunch, Posters and Demos</b></td>
			</tr>
			<tr>
				<td>14:00</td>
				<td><b>Session #4: Special Session GenAI and XR</b><br/>
					<ul>
						<li>Applications in Media for Novel View Synthesis<br/><i>Graeme Phillipson (BBC)*; Hell Raymond-Hayling (BBC); Alia Sheikh (BBC)</i></li>
						<li>Making Gen AI work for us, rather than the other way around<br/><i>Will MacNeil (The Mill)</i></li>
						<li>Overcoming Latency in Real-Time Virtual Production<br/><i>Dominic Brown (Disguise)</i></li>
						<li>Beyond Reality - Towards Creative Applications for Mixed Reality<br/><i>Thu Nguyen-Phuoc (Reality Labs Research at Meta)</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>15:20</td>
				<td><b>Coffee Break</b></td>
			</tr>
			<tr>
				<td>15:50</td>
				<td><a href="/2023/keynotes/#TM"><b>Keynote: Engines For Everything Except Games</b></a><br/>Tupac Martir, <i>Satore Studio</i></td>
			</tr>
			<tr>
				<td>16:50</td>
				<td><b>Closing</b><br/>Armin Mustafa, <i>University of Surrey</i></td>
			</tr>
		</table>
	</div>
</div>
