---
layout: cvmp-default
title: Keynotes
year: 2023
---

We are pleased to announce the following keynote speakers for CVMP 2023:


<a name="ER" />
<div class="row">
<div class="col-xs-12 col-sm-7 col-md-8 col-lg-9" markdown="1" style="text-align: justify">

#### Andrew Whitehurst, Industrial Light and Magic <br> The Magic of The Man in the Hat: Creating VFX for Indiana Jones and the Dial of Destiny

Andrew Whitehurst served as production Visual Effects Supervisor on Indiana Jones and the Dial of Destiny. The film features around 2350 visual effects shots, created over three years, using a wide range of technologies from traditional to state of the art. In this talk he will breakdown a handful of shots to explain the creative process from initial idea to completion, why certain techniques were selected for these shots, and why to succeed requires the use of the simplest of technologies, a pencil, as well as the most complex. 

*Andrew Whitehurst is a senior visual effects supervisor at Industrial Light and Magic with 25 years of experience. He has worked on films as diverse as Ex Machina, for which he won an Academy Award, Paddington, and Skyfall. His most recent project was Indiana Jones and the Dial of Destiny.*

</div>

<figure class="col-xs-6 col-sm-5 col-md-4 col-lg-3">
  <img src="{{site.url}}/img/2023/keynotes/AndrewWhitehurstHeadshot.jpg" class="img-responsive img-thumbnail" alt="Erik Reinhard" title="Erik Reinhard">
</figure>

</div>



<a name="ER" />
<div class="row">
<div class="col-xs-12 col-sm-7 col-md-8 col-lg-9" markdown="1" style="text-align: justify">

#### Duygu Ceylan, Adobe Research <br> Towards Multi-Modal Generation

We are witnessing an impressive pace of innovation happening in the generative AI space. 2D image domain is often at the frontier of this innovation followed by trends to extend the success to domains such as videos or 3D. While they seem as different domains, one can argue that these domains are in fact very much connected. In this talk, I will talk about some recent efforts that leverage the knowledge of foundational models trained for a particular domain to address tasks in other domains. I will also present thoughts around future opportunities that can leverage this tight connection to go towards universal generation models.

*Duygu Ceylan is senior research scientist at Adobe Research. Prior to joining Adobe in 2014, Duygu obtained her PhD degree from EPFL where I worked with Prof. Mark Pauly. She graduated from Computer Engineering Department of METU in 2007 and got my Masterâ€™s degree in CS from Bilkent University in 2009. Duygu received the Eurographics PhD Award in 2015 and the Eurographics Young Researcher Award in 2020. Her research interests include using machine learning techniques to infer and analyze 3D information from images and videos, focusing specifically on humans. She is excited to work at the intersection of computer vision and graphics where she explores new methods to bridge the gap between 2D & 3D.*

</div>

<figure class="col-xs-6 col-sm-5 col-md-4 col-lg-3">
  <img src="{{site.url}}/img/2023/keynotes/Duygu_Ceylan.png" class="img-responsive img-thumbnail" alt="Erik Reinhard" title="Erik Reinhard">
</figure>

</div>

<a name="ER" />
<div class="row">
<div class="col-xs-12 col-sm-7 col-md-8 col-lg-9" markdown="1" style="text-align: justify">

#### Jonathan Starck, Synthesia <br> Digital Humans in Generative Video

There has been an explosion of interest and adoption of Generative AI over the last few years, driven by the ability to generate human-level text, images, audio, and video. These techniques offer powerful tools to content creators to streamline the creation process, enhance creativity, and deliver personalised content at scale. The aim of this talk is to introduce the current trends and challenges in Generative AI, specifically for live-action content and visual storytelling. Synthesia focuses on democratising video creation for businesses, providing the ability to create photorealistic human avatars and enabling users to create professional videos using text as a simple and accessible interface. This brings particular challenges in creating controllable and life-like performances for digital humans in text-to-video.

*Jonathan Starck is CTO at Synthesia, a startup founded in 2017 and now a Generative AI Unicorn. Synthesia produces the world's #1 AI video generation platform that allows users to create professional live-action videos directly in the browser, removing the physical constraints of conventional production. No cameras, microphones, or studios. Just create, iterate and collaborate directly on final quality content using text as an interface. Prior to Synthesia, Jonathan was a Researcher on Digital Humans at the University of Surrey and then Head of Research at Foundry, introducing 3D computer tools to accelerate artist workflows in the Nuke Compositing system for Film VFX. At Synthesia he leads Research and Production and is responsible for generative humans - Synthesia "AI Avatars".*

</div>

<figure class="col-xs-6 col-sm-5 col-md-4 col-lg-3">
  <img src="{{site.url}}/img/2023/keynotes/Jon_Starck.png" class="img-responsive img-thumbnail" alt="Erik Reinhard" title="Erik Reinhard">
</figure>

</div>
