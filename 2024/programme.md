---
layout: cvmp-default
title: Conference Programme
year: 2024
---
##### Noted that this program is tentative and subject to change

[//]: # (<strong>Programme booklet:</strong>)

[//]: # ([CVMP 2023 Programme &#40;9.6 MB&#41;]&#40;{{ site.url }}/files/2023/CVMP23-brochure.pdf&#41;)

[//]: # ()
[//]: # (<strong>Conference proceedings:</strong>)

[//]: # ([ACM Digital Library]&#40;https://dl.acm.org/doi/proceedings/10.1145/3626495&#41;{:target="_blank"})


<div class="col-12 col-sm-12 col-lg-12">
	<a name="thursday"></a>
	<div class="panel panel-default">
		<div class="panel-heading"><b>Monday 18th November 2024</b></div>
		<table class="table table-striped">
			<tr>
				<td>09:00</td>
				<td><b>Registration opens</b></td>
			</tr>
			<tr>
				<td>09:20</td>
				<td><b>Welcome</b><br/>Armin Mustafa <i>University of Surrey</i> </td>
			</tr>
			<tr>
				<td>09:30</td>
				<td><b>Session #1: 3D Capture and Novel View Synthesis</b><br/>
					<ul>
						<li>High-Quality Facial Geometry from Sparse Heterogeneous Devices under Active Illumination<br/><i>Lewis Bridgeman, Gilles Rainer, Abhijeet Ghosh</i></li>
						<li>Enhanced Illumination Adjustment in 3D Outdoor Reconstructions via Shadow Removal through Color Transfer<br/><i>Herbert Potechius, Selvam Essaky, Gunasekaran Raja, Thomas Sikora, Sebastian Knorr</i></li>
						<li>RegSegField: Mask-Regularization and Hierarchical Segmentation for Novel View Synthesis from Sparse Inputs<br/><i>Kai Gu, Thomas Maugey, Knorr Sebastian, Christine Guillemot</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>10:30</td>
				<td><b>Coffee Break</b><br/><i></i></td>
			</tr>	
			<tr>
				<td>11:00</td>
				<td><a href="/2024/keynotes/#SE"><b>Keynote: TBD</b></a><br/>Sarah Ellis, <i>Royal Shakespeare Company</i></td>
			</tr>
			<tr>
				<td>12:00</td>
				<td><b>Spotlight Session-Short Papers and Demos</b><br/>
					<ul>
						<li>A New Dataset for Multi-Camera Frame Synthesis<br/><i>Conall Daly (Trinity College Dublin, Ireland)  Anil Kokaram (Trinity College Dublin, Ireland)</i></li>
						<li>TRACER: Modular Open-Source Framework for Real-Time XR Collaboration<br/><i>Jonas Trottnow (Filmakademie Baden-Württemberg GmbH) Simon Spielmann (Filmakademie Baden-Württemberg GmbH) Simon Haag (Filmakademie Baden-Württemberg GmbH) Francesco Andreussi (Filmakademie Baden-Württemberg GmbH)</i></li>
						<li>Detection and Re-Identification in the case of Horse Racing<br/><i>Will Binnings (University of Surrey) Sadegh Rahmaniboldaji (University of Surrey) Xu Dong (University of Surrey) Andrew Gilbert (University of Surrey)</i></li>
						<li>ATRA: An Adaptive Tick Rate Algorithm for Efficient Collaboration in Virtual Reality<br/><i>William Naylor (University of Warwick) Alan Chalmers (University of Warwick) Kurt Debattista (University of Warwick, UK)</i></li>
						<li>High Fidelity 3D Head Reconstruction with 2D Gaussian Splatting<br/><i>Anil Bas (Bournemouth University) Oleg Fryazinov (Bournemouth University) Xiaosong Yang (Bournemouth University) Callum Rex Reid (Visualskies Ltd)</i></li>
                        <li>A Novel Motion Control Workflow for Capturing and Reproducing Realistic Lens Flares<br/><i>Vincent Maurer (Filmakademie Baden-Württemberg)</i></li>
						<li>Efficient Audio-Visual Fusion for Video Classification using Attend-Fusion<br/><i>Mahrukh Awan (University of Surrey) Asmar Nadeem (University of Surrey) Armin Mustafa (University of Surrey)</i></li>
                        <li>2D or not 2D: Live broadcasting into a game engine using a pseudo-3D approach<br/><i>Graham Thomas (BBC) Fiona Rivera (BBC)</i></li>
						<li>Overcoming Spatial Limitations in Optical Motion Capture Using Nested Volumes<br/><i>Paulo Scatena (Independent Researcher)</i></li>
						<li>Single-Image Coherent Reconstruction of Object and Human<br/><i>Sarthak Batra (University of Surrey) Armin Mustafa (University of Surrey)</i></li>
						<li>A Preliminary Study on Real-Time Compositing for 2D Cel-Animation Production<br/><i>Takeshi Okuya (Waseda University) Brian Y Pascente (Rose-Hulman Institute of Technology)</i></li>
						<li>Synthesis of Realistic Tongue Movements for Speech Animation Using Gated Recurrent Units<br/><i>Jake G Mwangi-Powell (University of Surrey) Marco Volino (University of Surrey) Robert Kosk (Humain Studios) Neo Yang (University of Surrey)</i></li>
						<li>Efficient Multi-Scale 3D Gaussian Splatting<br/><i>Umar Farooq (University of Surrey)* Jean-Yves Guillemaut (University of Surrey) Adrian Hilton (University of Surrey) Marco Volino (University of Surrey)</i></li>	
                        <li>Audio-Driven 3D Gaussians for High-Fidelity Talking Head Synthesis at 120 FPS<br/><i>Kyusun Cho (Korea University) Seungryong Kim (Korea Advanced Institute of Science & Technology)</i></li>
						<li>MAX-R Demo: Digital Location<br/><i>Jonas Trottnow (Filmakademie Baden-Württemberg GmbH) Simon Spielmann (Filmakademie Baden-Württemberg GmbH) Volker Helzle (ANIMATIONSINSTITUT, FILMAKADEMIE, FMX) Alexandru-Sebastian Tufis-Schwartz (Filmakademie Baden-Württemberg GmbH)</i></li>
						<li>MAX-R Demo: AnimHost<br/><i>Jonas Trottnow (Filmakademie Baden-Württemberg GmbH) Simon Spielmann (Filmakademie Baden-Württemberg GmbH) Volker Helzle (ANIMATIONSINSTITUT, FILMAKADEMIE, FMX) Francesco Andreussi (Filmakademie Baden-Württemberg GmbH) Simon Haag (Filmakademie Baden-Würtemberg GmbH)</i></li>
						<li>Demonstrating Causal-Temporal Narrative Video Captioning using NarrativeBridge<br/><i>Asmar Nadeem (University of Surrey) Mahrukh Awan (University of Surrey) Armin Mustafa (University of Surrey)</i></li>
                        <li>Advancements in Networked Pipelines for Virtual Production<br/><i>Philip Coulam-Jones (Disguise) Kenneth Leung (Disguise) Josh McNamee (Disguise)</i></li>
						<li>EnVisualAIzer – Explorable AI-Generated Environments for All Filmmakers in Virtual Production<br/><i>Pauline Leininger (University of Television and Film Munich)</i></li>
                        <li>The Changing Forest: managing mass personalisation via audio-visual media flexibilities<br/><i>Craig Cieciura (University of Surrey) Maggie Kosek (University of Surrey) Elettra Bargiacchi (University of Surrey) Philip JB Jackson (University of Surrey)</i></li>
                        <li>AI-Driven Real-Time Visualization of Music<br/><i>Jenny Huang (University of Television and Film Munich)</i></li>
                    </ul>
				</td>
			</tr>
			<tr>
				<td>12:30</td>
				<td><b>Lunch, Posters and Demos</b></td>
			</tr>
			<tr>
				<td>14:00</td>
				<td><b>Session #2: Image Enhancement and Computational Photography</b><br/>
					<ul>
						<li>Optimal OLAT Alignment for Image-Based Relighting with Color-Multiplexed OLAT Sequence<br/><i>Arvin Lin, Abhijeet Ghosh </i></li>
						<li>Image-Based Material Editing Using Perceptual Attributes or Ground-Truth Parameters<br/><i>Victor Stenvers, Peter Vangorp</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>15:00</td>
				<td><b>CVMP Awards</b></td>
			</tr>
			<tr>
				<td>15:30</td>
				<td><b>Coffee Break</b></td>
			</tr>	
			<tr>
				<td>16:00</td>
				<td><a href="/2024/keynotes/#AS"><b>Keynote: Understanding user behavior and attention in immersive environments</b></a><br/>Ana Serrano, <i>Universidad de Zaragoza</i></td>
			</tr>
			<tr>
				<td>17:00</td>
				<td><b>Networking Reception</b></td>
			</tr>
		</table>
	</div>
	<a name="friday"></a>
	<div class="panel panel-default">
		<div class="panel-heading"><b>Tuesday 19th November 2024</b></div>
		<table class="table table-striped">
			<tr>
				<td>09:00</td>
				<td><b>Registration opens</b></td>
			</tr>
			<tr>
				<td>09:30</td>
				<td><b>Session #3: Human Motion, Privacy and Usability</b><br/>
					<ul>
						<li>Multi-Resolution Generative Modeling of Human Motion from Limited Data<br/><i>David E Moreno-Villamarin, Anna Hilsmann, Peter Eisert</i></li>
						<li>PDFed: Privacy-Preserving and Decentralized Asynchronous Federated Learning for Diffusion Models<br/><i>Kar Balan, Andrew Gilbert, John Collomosse</i></li>
						<li>Interacting from Afar: A Study of the Relationship Between Usability and Presence in Object Selection at a Distance<br/><i>Kalila Shapiro, Pedro Quijada Leyton, Lloyd Stemple, David Uberti</i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>10:30</td>
				<td><b>Coffee Break</b></td>
			</tr>	
			<tr>
				<td>11:00</td><td><a href="/2024/keynotes/#SS"><b>Keynote: TBD</b></a><br/>Shunsuke Saito, <i> Reality Labs Research, Meta</i></td>
			</tr>
			<tr>
				<td>12:00</td>
				<td><b>Lunch, Posters and Demos</b></td>
			</tr>
			<tr>
				<td>13:45</td>
				<td><b>Session #4: Industrial Session</b><br/>
					<ul>
						<li>John Collomosse, Adobe/Surrey University<br/><i></i></li>
						<li> Graham Jack, BeloFX<br/><i></i></li>
						<li>Armen Avetisyan, Meta<br/><i></i></li>
						<li>Graham Thomas, BBC R&D<br/><i></i></li>
					</ul>
				</td>
			</tr>
			<tr>
				<td>15:25</td>
				<td><b>Coffee Break</b></td>
			</tr>
			<tr>
				<td>15:50</td>
				<td><a href="/2024/keynotes/#AS"><b>Keynote: TBD</b></a><br/>Aljosa Smolic, <i> Lucerne University of Applied Sciences and Arts</i></td>
			</tr>
			<tr>
				<td>16:50</td>
				<td><b>Closing, Best Paper Awards</b><br/>Hansung Kim, <i>University of Southampton</i></td>
			</tr>
		</table>
	</div>
</div>
